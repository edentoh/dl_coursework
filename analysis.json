{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training curves + stats (Detector + CVS)\n",
        "\n",
        "This notebook reads your `history.jsonl` logs and plots:\n",
        "- Detector: `train_loss`, `val_map`\n",
        "- CVS: `train_loss`, `val_loss`, `val_macro_f1`, and per-criterion F1 (C1/C2/C3)\n",
        "\n",
        "It also prints the **best epoch** for each run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------------\n",
        "# EDIT THESE PATHS\n",
        "# ----------------------------\n",
        "# Set to your coursework folder that contains \"runs/\"\n",
        "PROJECT_ROOT = Path(r\"C:/Users/TUF/COMP0220_Deep_Learning/coursework\")\n",
        "\n",
        "# Baseline run folders (as in your config.toml)\n",
        "DETECTOR_RUN = PROJECT_ROOT / \"runs\" / \"detector_baseline\"\n",
        "CVS_RUN      = PROJECT_ROOT / \"runs\" / \"cvs_baseline\"\n",
        "\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"DETECTOR_RUN exists:\", DETECTOR_RUN.exists())\n",
        "print(\"CVS_RUN exists:\", CVS_RUN.exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_jsonl(path: Path) -> pd.DataFrame:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"Missing: {path}\")\n",
        "    rows = []\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            rows.append(json.loads(line))\n",
        "    if len(rows) == 0:\n",
        "        return pd.DataFrame()\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def safe_float(x):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "def add_cvs_percriterion_f1(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # per_criterion is a list of 3 dicts with key 'f1'\n",
        "    if \"per_criterion\" not in df.columns:\n",
        "        return df\n",
        "    def get_f1(idx):\n",
        "        out = []\n",
        "        for v in df[\"per_criterion\"].values:\n",
        "            try:\n",
        "                out.append(float(v[idx][\"f1\"]))\n",
        "            except Exception:\n",
        "                out.append(np.nan)\n",
        "        return out\n",
        "    df = df.copy()\n",
        "    df[\"f1_c1\"] = get_f1(0)\n",
        "    df[\"f1_c2\"] = get_f1(1)\n",
        "    df[\"f1_c3\"] = get_f1(2)\n",
        "    return df\n",
        "\n",
        "\n",
        "def best_epoch(df: pd.DataFrame, metric: str, mode: str = \"max\"):\n",
        "    if df.empty or metric not in df.columns:\n",
        "        return None\n",
        "    s = pd.to_numeric(df[metric], errors=\"coerce\")\n",
        "    if s.isna().all():\n",
        "        return None\n",
        "    i = s.idxmax() if mode == \"max\" else s.idxmin()\n",
        "    row = df.loc[i].to_dict()\n",
        "    return row\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "det_hist_path = DETECTOR_RUN / \"history.jsonl\"\n",
        "cvs_hist_path = CVS_RUN / \"history.jsonl\"\n",
        "\n",
        "det = read_jsonl(det_hist_path)\n",
        "cvs = read_jsonl(cvs_hist_path)\n",
        "cvs = add_cvs_percriterion_f1(cvs)\n",
        "\n",
        "print(\"Detector history rows:\", len(det))\n",
        "print(\"CVS history rows:\", len(cvs))\n",
        "\n",
        "display(det.tail(5))\n",
        "display(cvs.tail(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best epoch summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_det = best_epoch(det, \"val_map\", mode=\"max\")\n",
        "best_cvs = best_epoch(cvs, \"val_macro_f1\", mode=\"max\")\n",
        "\n",
        "print(\"=== Detector best (by val_map) ===\")\n",
        "print(best_det)\n",
        "\n",
        "print(\"\\n=== CVS best (by val_macro_f1) ===\")\n",
        "print(best_cvs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Detector curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if det.empty:\n",
        "    print(\"Detector history is empty.\")\n",
        "else:\n",
        "    det = det.copy()\n",
        "    det[\"epoch\"] = pd.to_numeric(det.get(\"epoch\", np.arange(1, len(det)+1)), errors=\"coerce\")\n",
        "    det[\"train_loss\"] = pd.to_numeric(det.get(\"train_loss\", np.nan), errors=\"coerce\")\n",
        "    det[\"val_map\"] = pd.to_numeric(det.get(\"val_map\", np.nan), errors=\"coerce\")\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(det[\"epoch\"], det[\"train_loss\"], marker=\"o\")\n",
        "    plt.title(\"Detector: train loss\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(det[\"epoch\"], det[\"val_map\"], marker=\"o\")\n",
        "    plt.title(\"Detector: val mAP@[.5:.95]\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"mAP\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot CVS curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cvs.empty:\n",
        "    print(\"CVS history is empty.\")\n",
        "else:\n",
        "    cvs = cvs.copy()\n",
        "    cvs[\"epoch\"] = pd.to_numeric(cvs.get(\"epoch\", np.arange(1, len(cvs)+1)), errors=\"coerce\")\n",
        "    for k in [\"train_loss\", \"val_loss\", \"val_macro_f1\", \"f1_c1\", \"f1_c2\", \"f1_c3\"]:\n",
        "        if k in cvs.columns:\n",
        "            cvs[k] = pd.to_numeric(cvs[k], errors=\"coerce\")\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(cvs[\"epoch\"], cvs[\"train_loss\"], marker=\"o\", label=\"train_loss\")\n",
        "    plt.plot(cvs[\"epoch\"], cvs[\"val_loss\"], marker=\"o\", label=\"val_loss\")\n",
        "    plt.title(\"CVS: loss\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(cvs[\"epoch\"], cvs[\"val_macro_f1\"], marker=\"o\")\n",
        "    plt.title(\"CVS: val macro-F1\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"macro-F1\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    if \"f1_c1\" in cvs.columns:\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.plot(cvs[\"epoch\"], cvs[\"f1_c1\"], marker=\"o\", label=\"C1\")\n",
        "        plt.plot(cvs[\"epoch\"], cvs[\"f1_c2\"], marker=\"o\", label=\"C2\")\n",
        "        plt.plot(cvs[\"epoch\"], cvs[\"f1_c3\"], marker=\"o\", label=\"C3\")\n",
        "        plt.title(\"CVS: per-criterion F1\")\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(\"F1\")\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Compare multiple runs automatically\n",
        "\n",
        "If you create `runs/detector_*` or `runs/cvs_*`, this cell will list them and plot `val_map` / `val_macro_f1`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUNS_ROOT = PROJECT_ROOT / \"runs\"\n",
        "det_runs = sorted([p for p in RUNS_ROOT.glob(\"detector*\") if (p / \"history.jsonl\").exists()])\n",
        "cvs_runs = sorted([p for p in RUNS_ROOT.glob(\"cvs*\") if (p / \"history.jsonl\").exists()])\n",
        "\n",
        "print(\"Detector runs:\")\n",
        "for p in det_runs:\n",
        "    print(\" -\", p.name)\n",
        "\n",
        "print(\"\\nCVS runs:\")\n",
        "for p in cvs_runs:\n",
        "    print(\" -\", p.name)\n",
        "\n",
        "# Plot val_map across detector runs\n",
        "if len(det_runs) > 1:\n",
        "    plt.figure(figsize=(9, 4))\n",
        "    for run in det_runs:\n",
        "        df = read_jsonl(run / \"history.jsonl\")\n",
        "        if \"epoch\" not in df.columns or \"val_map\" not in df.columns:\n",
        "            continue\n",
        "        df[\"epoch\"] = pd.to_numeric(df[\"epoch\"], errors=\"coerce\")\n",
        "        df[\"val_map\"] = pd.to_numeric(df[\"val_map\"], errors=\"coerce\")\n",
        "        plt.plot(df[\"epoch\"], df[\"val_map\"], marker=\"o\", label=run.name)\n",
        "    plt.title(\"Detector runs: val mAP\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"mAP\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Plot val_macro_f1 across cvs runs\n",
        "if len(cvs_runs) > 1:\n",
        "    plt.figure(figsize=(9, 4))\n",
        "    for run in cvs_runs:\n",
        "        df = read_jsonl(run / \"history.jsonl\")\n",
        "        if \"epoch\" not in df.columns or \"val_macro_f1\" not in df.columns:\n",
        "            continue\n",
        "        df[\"epoch\"] = pd.to_numeric(df[\"epoch\"], errors=\"coerce\")\n",
        "        df[\"val_macro_f1\"] = pd.to_numeric(df[\"val_macro_f1\"], errors=\"coerce\")\n",
        "        plt.plot(df[\"epoch\"], df[\"val_macro_f1\"], marker=\"o\", label=run.name)\n",
        "    plt.title(\"CVS runs: val macro-F1\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"macro-F1\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
